{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "293bea16",
   "metadata": {},
   "source": [
    "# Term Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817d67ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def termFrequencyInDoc(vocab,doc_dict):\n",
    "    tf_docs = {}\n",
    "    for doc_id in doc_dict.keys():\n",
    "        tf_docs[doc_id]={}\n",
    "    \n",
    "    for word in vocab:\n",
    "        for doc_id, doc in doc_dict.items():\n",
    "            tf_docs[doc_id][word]=doc.count(word)\n",
    "    return tf_docs\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b590cde9",
   "metadata": {},
   "source": [
    "Fungsi di atas digunakan untuk penghitungan raw tf. Anda dapat melakukan modifikasi untuk\n",
    "menghitung versi tf yang lain, seperti binary tf, normalized tf dan logarithmic tf.\n",
    "Kemudian, panggil fungsi tersebut dengan memasukkan vocab dan doc_dict sebagai parameter.\n",
    "Vocab adalah suatu list yang berisi kumpulan term pada corpus. Anda dapat menggunakan\n",
    "inverted_index pada praktikum sebelumnya untuk mendapatkan daftar vocabulary pada\n",
    "corpus. Sedangkan doc_dict adalah dictionary yang terdiri dari isi dokumen (kalimat atau\n",
    "paragraf) yang telah dilakukan preprocessing dengan doc_id sebagai key-nya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7ccfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kembang': [1, 2], 'sistem': [1, 3], 'informasi': [1], 'jadwal': [1], 'model': [2], 'analisis': [2, 3], 'sentimen': [2], 'berita': [2], 'input': [3], 'output': [3]}\n"
     ]
    }
   ],
   "source": [
    "doc1_term=[\"pengembangan\",\"sistem\",\"informasi\",\"penjadwalan\"]\n",
    "doc2_term=[\"pengembangan\",\"model\",\"analisis\",\"sentimen\",\"berita\"]\n",
    "doc3_term=[\"analisis\",\"sistem\",\"input\",\"output\"]\n",
    "\n",
    "corpus_term=[doc1_term,doc2_term,doc3_term]\n",
    "\n",
    "def tokenisasi(text):\n",
    "    output = text.split(\" \")\n",
    "    return output\n",
    "\n",
    "def stemming(text): \n",
    "    from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "    #create stemmer\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "\n",
    "    output=stemmer.stem(text)\n",
    "    #s=stopworded(output)\n",
    "    return output\n",
    "\n",
    "\n",
    "inverted_index = {}\n",
    " \n",
    "for i in range(len(corpus_term)):\n",
    "    for item in corpus_term[i]:\n",
    "        item = stemming(item)\n",
    "        if item not in inverted_index:\n",
    "            inverted_index[item] = []\n",
    "        if (item in inverted_index) and ((i+1) not in inverted_index[item]):\n",
    "            inverted_index[item].append(i+1)\n",
    "print(inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7a17cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc1': 'kembang sistem informasi jadwal', 'doc2': 'kembang model analisis sentimen berita', 'doc3': 'analisis sistem input output'}\n"
     ]
    }
   ],
   "source": [
    "vocab = list(inverted_index.keys())\n",
    "doc_dict={}\n",
    "#clean after stemming\n",
    "doc_dict['doc1']=\"kembang sistem informasi jadwal\"\n",
    "doc_dict['doc2']=\"kembang model analisis sentimen berita\"\n",
    "doc_dict['doc3']=\"analisis sistem input output\"\n",
    "\n",
    "#print(termFrequencyInDoc(vocab,doc_dict))\n",
    "print(doc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6286e70a",
   "metadata": {},
   "source": [
    "Kemudian buat fungsi berikut untuk menghitung document frequency and inverse document\n",
    "frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00078a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kembang': 2, 'sistem': 2, 'informasi': 1, 'jadwal': 1, 'model': 1, 'analisis': 2, 'sentimen': 1, 'berita': 1, 'input': 1, 'output': 1}\n"
     ]
    }
   ],
   "source": [
    "def wordDocFre(vocab,doc_dict):\n",
    "    df={}\n",
    "    for word in vocab:\n",
    "        frq = 0\n",
    "        for doc in doc_dict.values():\n",
    "            if word in tokenisasi(doc):\n",
    "                frq=frq+1\n",
    "        df[word]=frq\n",
    "    return df\n",
    "\n",
    "print(wordDocFre(vocab,doc_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3c3a934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kembang': 1.4771212547196624, 'sistem': 1.4771212547196624, 'informasi': 1.6989700043360187, 'jadwal': 1.6989700043360187, 'model': 1.6989700043360187, 'analisis': 1.4771212547196624, 'sentimen': 1.6989700043360187, 'berita': 1.6989700043360187, 'input': 1.6989700043360187, 'output': 1.6989700043360187}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def inverseDocFre(vocab,doc_fre,length):\n",
    "    idf={}\n",
    "    for word in vocab:\n",
    "        idf[word]=idf[word]=1+np.log10((length+1)/doc_fre[word]+1)\n",
    "    return idf\n",
    "    \n",
    "#check\n",
    "print(inverseDocFre(vocab,wordDocFre(vocab,doc_dict),len(doc_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc19da",
   "metadata": {},
   "source": [
    "# Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d05ab051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(vocab,tf,idf_scr,doc_dict):\n",
    "    tf_idf_scr={}\n",
    "    for doc_id in doc_dict.keys():\n",
    "        tf_idf_scr[doc_id]={}\n",
    "    for word in vocab:\n",
    "        for doc_id, doc in doc_dict.items():\n",
    "            tf_idf_scr[doc_id][word] = tf[doc_id][word]*idf_scr[word]\n",
    "    return tf_idf_scr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac17d40b",
   "metadata": {},
   "source": [
    "Panggil fungsi di atas sehingga Anda dapat menghasilkan suatu term-document matrix dengan skor\n",
    "tf.idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "034cec44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc1': {'kembang': 1.4771212547196624, 'sistem': 1.4771212547196624, 'informasi': 1.6989700043360187, 'jadwal': 1.6989700043360187, 'model': 0.0, 'analisis': 0.0, 'sentimen': 0.0, 'berita': 0.0, 'input': 0.0, 'output': 0.0}, 'doc2': {'kembang': 1.4771212547196624, 'sistem': 0.0, 'informasi': 0.0, 'jadwal': 0.0, 'model': 1.6989700043360187, 'analisis': 1.4771212547196624, 'sentimen': 1.6989700043360187, 'berita': 1.6989700043360187, 'input': 0.0, 'output': 0.0}, 'doc3': {'kembang': 0.0, 'sistem': 1.4771212547196624, 'informasi': 0.0, 'jadwal': 0.0, 'model': 0.0, 'analisis': 1.4771212547196624, 'sentimen': 0.0, 'berita': 0.0, 'input': 1.6989700043360187, 'output': 1.6989700043360187}}\n",
      "[[1.47712125 1.47712125 0.        ]\n",
      " [1.47712125 0.         1.47712125]\n",
      " [1.69897    0.         0.        ]\n",
      " [1.69897    0.         0.        ]\n",
      " [0.         1.69897    0.        ]\n",
      " [0.         1.47712125 1.47712125]\n",
      " [0.         1.69897    0.        ]\n",
      " [0.         1.69897    0.        ]\n",
      " [0.         0.         1.69897   ]\n",
      " [0.         0.         1.69897   ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf_idf = tfidf(vocab, termFrequencyInDoc(vocab,doc_dict),inverseDocFre(vocab,wordDocFre(vocab,doc_dict),len(doc_dict)),doc_dict)\n",
    "print(tf_idf)\n",
    "\n",
    "#Term - Document Matrix\n",
    "\n",
    "TD = np.zeros((len(vocab),len(doc_dict)))\n",
    "for word in vocab:\n",
    "    for doc_id, doc in tf_idf.items():\n",
    "        ind1=vocab.index(word)\n",
    "        ind2=list(tf_idf.keys()).index(doc_id)\n",
    "        TD[ind1][ind2]=tf_idf[doc_id][word]\n",
    "print(TD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a473d1",
   "metadata": {},
   "source": [
    "# Ukuran Kemiripan Teks"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48841671",
   "metadata": {},
   "source": [
    "Edit Distance\n",
    "Diketahui terdapat dua dokumen, kemiripan teks dengan edit distance dapat dihitung\n",
    "dengan fungsi berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37e7fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(string1, string2):\n",
    "    if len(string1)>len(string2):\n",
    "        difference = len(string1)-len(string2)\n",
    "        string1[:difference]\n",
    "        n = len(string2)\n",
    "    elif len(string2)>len(string1):\n",
    "        difference = len(string2)-len(string1)\n",
    "        string2[:difference]\n",
    "        n=len(string1)\n",
    "    for i in range(n):\n",
    "        if string1[i]!=string2[i]:\n",
    "            difference+=1\n",
    "            \n",
    "    return difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7cd900",
   "metadata": {},
   "source": [
    "Kemudian panggil fungsi di atas untuk menghitung kemiripan antara doc1 dan doc2 pada\n",
    "doc_dict yang digunakan pada praktikum sebelumnya, serta kemiripan antara doc1\n",
    "dan doc3. Analisis hasil kemiripan tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3803b3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "print(edit_distance(doc_dict['doc1'],doc_dict['doc2']))\n",
    "print(edit_distance(doc_dict['doc1'],doc_dict['doc3']))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d8043cf",
   "metadata": {},
   "source": [
    "Jaccard Similarity\n",
    "Diketahui terdapat dua dokumen, kemiripan teks dengan jaccard similarity dapat dihitung\n",
    "dengan fungsi berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a560012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_sim(list1,list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = len(list1)+len(list2)-intersection\n",
    "    \n",
    "    return float(intersection)/union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a92fef",
   "metadata": {},
   "source": [
    "Kemudian panggil fungsi di atas untuk menghitung kemiripan antara doc1 dan doc2 pada\n",
    "doc_dict yang digunakan pada praktikum sebelumnya, serta kemiripan antara doc1\n",
    "dan doc3. Analisis hasil kemiripan tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c0c3e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125\n",
      "0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "print(jaccard_sim(doc_dict['doc1'].split(\" \"),doc_dict['doc2'].split(\" \")))\n",
    "print(jaccard_sim(doc_dict['doc1'].split(\" \"),doc_dict['doc3'].split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c41f3d",
   "metadata": {},
   "source": [
    "Euclidian Distance\n",
    "Diketahui terdapat dua dokumen, kemiripan teks dengan euclidian distance dapat dihitung\n",
    "dengan fungsi berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5c389a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_dist(vec1,vec2):\n",
    "    #substracting vector\n",
    "    temp=vec1-vec2\n",
    "    \n",
    "    #doing dot product\n",
    "    #for finding\n",
    "    #sum of squares\n",
    "    sum_sq = np.dot(temp.T,temp)\n",
    "\n",
    "    #Doing squareroot and \n",
    "    #printing euclidian distance\n",
    "    return np.sqrt(sum_sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a8247c",
   "metadata": {},
   "source": [
    "Kemudian panggil fungsi di atas untuk menghitung kemiripan antara doc1 dan doc2 pada\n",
    "doc_dict yang digunakan pada praktikum sebelumnya dengan melakukan slicing pada\n",
    "term-document matrix, serta kemiripan antara doc1 dan doc3. Analisis hasil kemiripan\n",
    "tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3719a223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3354665009035465\n",
      "3.9887053920819104\n",
      "[[1.47712125 1.47712125 0.        ]\n",
      " [1.47712125 0.         1.47712125]\n",
      " [1.69897    0.         0.        ]\n",
      " [1.69897    0.         0.        ]\n",
      " [0.         1.69897    0.        ]\n",
      " [0.         1.47712125 1.47712125]\n",
      " [0.         1.69897    0.        ]\n",
      " [0.         1.69897    0.        ]\n",
      " [0.         0.         1.69897   ]\n",
      " [0.         0.         1.69897   ]]\n"
     ]
    }
   ],
   "source": [
    "print(euclidian_dist(TD[:,0],TD[:,1])) #doc 1 dan 2\n",
    "print(euclidian_dist(TD[:,0],TD[:,2])) #doc 1 dan 3\n",
    "print(TD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07e5af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def cosine_sim(vec1,vec2):\n",
    "    vec1=list(vec1)\n",
    "    vec2=list(vec2)\n",
    "    dot_prod=0\n",
    "    for i, v in enumerate(vec1):\n",
    "        dot_prod+=v*vec2[i]\n",
    "    mag_1=math.sqrt(sum([x**2 for x in vec1]))\n",
    "    mag_2=math.sqrt(sum([x**2 for x in vec2]))\n",
    "    return dot_prod/(mag_1 * mag_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd2150c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18989887606389028\n",
      "0.2152447625333299\n"
     ]
    }
   ],
   "source": [
    "print(cosine_sim(TD[:,0],TD[:,1]))\n",
    "print(cosine_sim(TD[:,0],TD[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce72e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20694271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bff60dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d0b343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0fc2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9731a098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
