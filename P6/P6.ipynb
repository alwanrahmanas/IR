{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "655ac598",
   "metadata": {},
   "source": [
    "### Evaluasi untuk Unranked Retrieval Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ce65e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc1': 'kembang sistem informasi jadwal', 'doc2': 'kembang model analisis sentimen berita', 'doc3': 'analisis sistem input output', 'doc4': 'kembang sistem informasi akademik universitas', 'doc5': 'kembang sistem cari berita ekonomi', 'doc6': 'analisis sistem neraca nasional', 'doc7': 'kembang sistem informasi layan statistik', 'doc8': 'kembang sistem cari skripsi di universitas', 'doc9': 'analisis sentimen publik hadap perintah', 'doc10': 'kembang model klasifikasi sentimen berita'}\n"
     ]
    }
   ],
   "source": [
    "def tokenisasi(text):\n",
    "    tokens = text.split(\" \")\n",
    "    return tokens\n",
    "\n",
    "def stemming(text):\n",
    "    from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "    # create stemmer\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    # stemming process\n",
    "    output = stemmer.stem(text)\n",
    "    return output\n",
    "\n",
    "def stemming_sentence(text):\n",
    "    output = \"\"\n",
    "    for token in tokenisasi(text):\n",
    "        output = output + stemming(token) + \" \"\n",
    "    return output[:-1]\n",
    "\n",
    "doc_dict_raw = {}\n",
    "doc_dict_raw['doc1'] = \"pengembangan sistem informasi penjadwalan\"\n",
    "doc_dict_raw['doc2'] = \"pengembangan model analisis sentimen berita\"\n",
    "doc_dict_raw['doc3'] = \"analisis sistem input output\"\n",
    "doc_dict_raw['doc4'] = \"pengembangan sistem informasi akademik universitas\"\n",
    "doc_dict_raw['doc5'] = \"pengembangan sistem cari berita ekonomi\"\n",
    "doc_dict_raw['doc6'] = \"analisis sistem neraca nasional\"\n",
    "doc_dict_raw['doc7'] = \"pengembangan sistem informasi layanan statistik\"\n",
    "doc_dict_raw['doc8'] = \"pengembangan sistem pencarian skripsi di universitas\"\n",
    "doc_dict_raw['doc9'] = \"analisis sentimen publik terhadap pemerintah\"\n",
    "doc_dict_raw['doc10'] = \"pengembangan model klasifikasi sentimen berita\"\n",
    "\n",
    "doc_dict = {}\n",
    "for doc_id,doc in doc_dict_raw.items():\n",
    "    doc_dict[doc_id] = stemming_sentence(doc)\n",
    "\n",
    "print(doc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9eed5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kembang\n",
      "sistem\n",
      "informasi\n",
      "jadwal\n",
      "kembang\n",
      "model\n",
      "analisis\n",
      "sentimen\n",
      "berita\n",
      "analisis\n",
      "sistem\n",
      "input\n",
      "output\n",
      "kembang\n",
      "sistem\n",
      "informasi\n",
      "akademik\n",
      "universitas\n",
      "kembang\n",
      "sistem\n",
      "cari\n",
      "berita\n",
      "ekonomi\n",
      "analisis\n",
      "sistem\n",
      "neraca\n",
      "nasional\n",
      "kembang\n",
      "sistem\n",
      "informasi\n",
      "layan\n",
      "statistik\n",
      "kembang\n",
      "sistem\n",
      "cari\n",
      "skripsi\n",
      "di\n",
      "universitas\n",
      "analisis\n",
      "sentimen\n",
      "publik\n",
      "hadap\n",
      "perintah\n",
      "kembang\n",
      "model\n",
      "klasifikasi\n",
      "sentimen\n",
      "berita\n",
      "['kembang', 'sistem', 'informasi', 'jadwal', 'model', 'analisis', 'sentimen', 'berita', 'input', 'output', 'akademik', 'universitas', 'cari', 'ekonomi', 'neraca', 'nasional', 'layan', 'statistik', 'skripsi', 'di', 'publik', 'hadap', 'perintah', 'klasifikasi']\n",
      "{'kembang': ['doc1', 'doc2', 'doc4', 'doc5', 'doc7', 'doc8', 'doc10'], 'sistem': ['doc1', 'doc3', 'doc4', 'doc5', 'doc6', 'doc7', 'doc8'], 'informasi': ['doc1', 'doc4', 'doc7'], 'jadwal': ['doc1'], 'model': ['doc2', 'doc10'], 'analisis': ['doc2', 'doc3', 'doc6', 'doc9'], 'sentimen': ['doc2', 'doc9', 'doc10'], 'berita': ['doc2', 'doc5', 'doc10'], 'input': ['doc3'], 'output': ['doc3'], 'akademik': ['doc4'], 'universitas': ['doc4', 'doc8'], 'cari': ['doc5', 'doc8'], 'ekonomi': ['doc5'], 'neraca': ['doc6'], 'nasional': ['doc6'], 'layan': ['doc7'], 'statistik': ['doc7'], 'skripsi': ['doc8'], 'di': ['doc8'], 'publik': ['doc9'], 'hadap': ['doc9'], 'perintah': ['doc9'], 'klasifikasi': ['doc10']}\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "inverted_index = {}\n",
    "for doc_id,doc in doc_dict.items():\n",
    "    for token in tokenisasi(doc):\n",
    "        print(token)\n",
    "        if token not in vocab:\n",
    "            vocab.append(token)\n",
    "            inverted_index[token] = []\n",
    "        if token in inverted_index:\n",
    "            if doc_id not in inverted_index[token]:\n",
    "                inverted_index[token].append(doc_id)\n",
    "print(vocab)\n",
    "print(inverted_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ff80cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kembang': 0, 'sistem': 1, 'informasi': 1, 'jadwal': 0, 'model': 0, 'analisis': 0, 'sentimen': 0, 'berita': 0, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 0, 'cari': 0, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 1, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}\n"
     ]
    }
   ],
   "source": [
    "query = \"sistem informasi statistik\"\n",
    "def termFrequency(vocab, query):\n",
    "    tf_query = {}\n",
    "    for word in vocab:\n",
    "        tf_query[word] = query.count(word)\n",
    "    return tf_query\n",
    "\n",
    "tf_query = termFrequency(vocab, query)\n",
    "print(tf_query)\n",
    "#banyak kemunculan vocab di query(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae8239a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc1': {'kembang': 1, 'sistem': 1, 'informasi': 1, 'jadwal': 1, 'model': 0, 'analisis': 0, 'sentimen': 0, 'berita': 0, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 0, 'cari': 0, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 0, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}, 'doc2': {'kembang': 1, 'sistem': 0, 'informasi': 0, 'jadwal': 0, 'model': 1, 'analisis': 1, 'sentimen': 1, 'berita': 1, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 0, 'cari': 0, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 0, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}, 'doc3': {'kembang': 0, 'sistem': 1, 'informasi': 0, 'jadwal': 0, 'model': 0, 'analisis': 1, 'sentimen': 0, 'berita': 0, 'input': 1, 'output': 1, 'akademik': 0, 'universitas': 0, 'cari': 0, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 0, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}, 'doc4': {'kembang': 1, 'sistem': 1, 'informasi': 1, 'jadwal': 0, 'model': 0, 'analisis': 0, 'sentimen': 0, 'berita': 0, 'input': 0, 'output': 0, 'akademik': 1, 'universitas': 1, 'cari': 0, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 0, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}, 'doc5': {'kembang': 1, 'sistem': 1, 'informasi': 0, 'jadwal': 0, 'model': 0, 'analisis': 0, 'sentimen': 0, 'berita': 1, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 0, 'cari': 1, 'ekonomi': 1, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 0, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}, 'doc6': {'kembang': 0, 'sistem': 1, 'informasi': 0, 'jadwal': 0, 'model': 0, 'analisis': 1, 'sentimen': 0, 'berita': 0, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 0, 'cari': 0, 'ekonomi': 0, 'neraca': 1, 'nasional': 1, 'layan': 0, 'statistik': 0, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}, 'doc7': {'kembang': 1, 'sistem': 1, 'informasi': 1, 'jadwal': 0, 'model': 0, 'analisis': 0, 'sentimen': 0, 'berita': 0, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 0, 'cari': 0, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 1, 'statistik': 1, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}, 'doc8': {'kembang': 1, 'sistem': 1, 'informasi': 0, 'jadwal': 0, 'model': 0, 'analisis': 0, 'sentimen': 0, 'berita': 0, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 1, 'cari': 1, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 0, 'skripsi': 1, 'di': 1, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 0}, 'doc9': {'kembang': 0, 'sistem': 0, 'informasi': 0, 'jadwal': 0, 'model': 0, 'analisis': 1, 'sentimen': 1, 'berita': 0, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 0, 'cari': 0, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 0, 'skripsi': 0, 'di': 0, 'publik': 1, 'hadap': 1, 'perintah': 1, 'klasifikasi': 0}, 'doc10': {'kembang': 1, 'sistem': 0, 'informasi': 0, 'jadwal': 0, 'model': 1, 'analisis': 0, 'sentimen': 1, 'berita': 1, 'input': 0, 'output': 0, 'akademik': 0, 'universitas': 0, 'cari': 0, 'ekonomi': 0, 'neraca': 0, 'nasional': 0, 'layan': 0, 'statistik': 0, 'skripsi': 0, 'di': 0, 'publik': 0, 'hadap': 0, 'perintah': 0, 'klasifikasi': 1}}\n"
     ]
    }
   ],
   "source": [
    "def termFrequencyInDoc(vocab, doc_dict):\n",
    "    tf_docs = {}\n",
    "    for doc_id in doc_dict.keys():\n",
    "        tf_docs[doc_id] = {} #create key dari tf_docs sebanyak doc_id\n",
    "    for word in vocab:\n",
    "        for doc_id, doc in doc_dict.items():\n",
    "            tf_docs[doc_id][word] = doc.count(word)\n",
    "    return tf_docs\n",
    "\n",
    "print(termFrequencyInDoc(vocab,doc_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a35f5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kembang': 7, 'sistem': 7, 'informasi': 3, 'jadwal': 1, 'model': 2, 'analisis': 4, 'sentimen': 3, 'berita': 3, 'input': 1, 'output': 1, 'akademik': 1, 'universitas': 2, 'cari': 2, 'ekonomi': 1, 'neraca': 1, 'nasional': 1, 'layan': 1, 'statistik': 1, 'skripsi': 1, 'di': 1, 'publik': 1, 'hadap': 1, 'perintah': 1, 'klasifikasi': 1}\n"
     ]
    }
   ],
   "source": [
    "def tokenisasi(text):\n",
    "    tokens =  text.split(\" \")\n",
    "    return tokens\n",
    "\n",
    "def wordDocFre(vocab,doc_dict):\n",
    "    df = {}\n",
    "    for word in vocab:\n",
    "        frq = 0\n",
    "        for doc in doc_dict.values():\n",
    "            if word in tokenisasi(doc):\n",
    "                frq = frq + 1\n",
    "        df[word] = frq\n",
    "    return df\n",
    "print(wordDocFre(vocab,doc_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdc46b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def inverseDocFre(vocab,doc_fre,length):\n",
    "    idf = {}\n",
    "    for word in vocab:\n",
    "        idf[word] = idf[word] = 1 + np.log10((length + 1) / (doc_fre[word]+1))\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b93cdf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kembang': 1.1383026981662814, 'sistem': 1.1383026981662814, 'informasi': 1.4393326938302626, 'jadwal': 1.7403626894942439, 'model': 1.5642714304385625, 'analisis': 1.3424226808222062, 'sentimen': 1.4393326938302626, 'berita': 1.4393326938302626, 'input': 1.7403626894942439, 'output': 1.7403626894942439, 'akademik': 1.7403626894942439, 'universitas': 1.5642714304385625, 'cari': 1.5642714304385625, 'ekonomi': 1.7403626894942439, 'neraca': 1.7403626894942439, 'nasional': 1.7403626894942439, 'layan': 1.7403626894942439, 'statistik': 1.7403626894942439, 'skripsi': 1.7403626894942439, 'di': 1.7403626894942439, 'publik': 1.7403626894942439, 'hadap': 1.7403626894942439, 'perintah': 1.7403626894942439, 'klasifikasi': 1.7403626894942439}\n"
     ]
    }
   ],
   "source": [
    "idf = inverseDocFre(vocab,wordDocFre(vocab,doc_dict),len(doc_dict))\n",
    "print(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4a45dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc1': {'kembang': 1.1383026981662814, 'sistem': 1.1383026981662814, 'informasi': 1.4393326938302626, 'jadwal': 1.7403626894942439, 'model': 0.0, 'analisis': 0.0, 'sentimen': 0.0, 'berita': 0.0, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc2': {'kembang': 1.1383026981662814, 'sistem': 0.0, 'informasi': 0.0, 'jadwal': 0.0, 'model': 1.5642714304385625, 'analisis': 1.3424226808222062, 'sentimen': 1.4393326938302626, 'berita': 1.4393326938302626, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc3': {'kembang': 0.0, 'sistem': 1.1383026981662814, 'informasi': 0.0, 'jadwal': 0.0, 'model': 0.0, 'analisis': 1.3424226808222062, 'sentimen': 0.0, 'berita': 0.0, 'input': 1.7403626894942439, 'output': 1.7403626894942439, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc4': {'kembang': 1.1383026981662814, 'sistem': 1.1383026981662814, 'informasi': 1.4393326938302626, 'jadwal': 0.0, 'model': 0.0, 'analisis': 0.0, 'sentimen': 0.0, 'berita': 0.0, 'input': 0.0, 'output': 0.0, 'akademik': 1.7403626894942439, 'universitas': 1.5642714304385625, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc5': {'kembang': 1.1383026981662814, 'sistem': 1.1383026981662814, 'informasi': 0.0, 'jadwal': 0.0, 'model': 0.0, 'analisis': 0.0, 'sentimen': 0.0, 'berita': 1.4393326938302626, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 1.5642714304385625, 'ekonomi': 1.7403626894942439, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc6': {'kembang': 0.0, 'sistem': 1.1383026981662814, 'informasi': 0.0, 'jadwal': 0.0, 'model': 0.0, 'analisis': 1.3424226808222062, 'sentimen': 0.0, 'berita': 0.0, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 1.7403626894942439, 'nasional': 1.7403626894942439, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc7': {'kembang': 1.1383026981662814, 'sistem': 1.1383026981662814, 'informasi': 1.4393326938302626, 'jadwal': 0.0, 'model': 0.0, 'analisis': 0.0, 'sentimen': 0.0, 'berita': 0.0, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 1.7403626894942439, 'statistik': 1.7403626894942439, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc8': {'kembang': 1.1383026981662814, 'sistem': 1.1383026981662814, 'informasi': 0.0, 'jadwal': 0.0, 'model': 0.0, 'analisis': 0.0, 'sentimen': 0.0, 'berita': 0.0, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 1.5642714304385625, 'cari': 1.5642714304385625, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 1.7403626894942439, 'di': 1.7403626894942439, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 0.0}, 'doc9': {'kembang': 0.0, 'sistem': 0.0, 'informasi': 0.0, 'jadwal': 0.0, 'model': 0.0, 'analisis': 1.3424226808222062, 'sentimen': 1.4393326938302626, 'berita': 0.0, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 1.7403626894942439, 'hadap': 1.7403626894942439, 'perintah': 1.7403626894942439, 'klasifikasi': 0.0}, 'doc10': {'kembang': 1.1383026981662814, 'sistem': 0.0, 'informasi': 0.0, 'jadwal': 0.0, 'model': 1.5642714304385625, 'analisis': 0.0, 'sentimen': 1.4393326938302626, 'berita': 1.4393326938302626, 'input': 0.0, 'output': 0.0, 'akademik': 0.0, 'universitas': 0.0, 'cari': 0.0, 'ekonomi': 0.0, 'neraca': 0.0, 'nasional': 0.0, 'layan': 0.0, 'statistik': 0.0, 'skripsi': 0.0, 'di': 0.0, 'publik': 0.0, 'hadap': 0.0, 'perintah': 0.0, 'klasifikasi': 1.7403626894942439}}\n"
     ]
    }
   ],
   "source": [
    "def tfidf(vocab,tf,idf_scr,doc_dict):\n",
    "    tf_idf_scr = {}\n",
    "    for doc_id in doc_dict.keys():\n",
    "        tf_idf_scr[doc_id] = {}\n",
    "    for word in vocab:\n",
    "        for doc_id, doc in doc_dict.items():\n",
    "            tf_idf_scr[doc_id][word] = tf[doc_id][word]*idf_scr[word]\n",
    "    return tf_idf_scr\n",
    "\n",
    "tf_idf = tfidf(vocab, termFrequencyInDoc(vocab,doc_dict),inverseDocFre(vocab,wordDocFre(vocab,doc_dict),len(doc_dict)),doc_dict)\n",
    "print(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09af62f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.1383027  1.1383027  0.         1.1383027  1.1383027  0.\n",
      "  1.1383027  1.1383027  0.         1.1383027 ]\n",
      " [1.1383027  0.         1.1383027  1.1383027  1.1383027  1.1383027\n",
      "  1.1383027  1.1383027  0.         0.        ]\n",
      " [1.43933269 0.         0.         1.43933269 0.         0.\n",
      "  1.43933269 0.         0.         0.        ]\n",
      " [1.74036269 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         1.56427143 0.         0.         0.         0.\n",
      "  0.         0.         0.         1.56427143]\n",
      " [0.         1.34242268 1.34242268 0.         0.         1.34242268\n",
      "  0.         0.         1.34242268 0.        ]\n",
      " [0.         1.43933269 0.         0.         0.         0.\n",
      "  0.         0.         1.43933269 1.43933269]\n",
      " [0.         1.43933269 0.         0.         1.43933269 0.\n",
      "  0.         0.         0.         1.43933269]\n",
      " [0.         0.         1.74036269 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         1.74036269 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         1.74036269 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         1.56427143 0.         0.\n",
      "  0.         1.56427143 0.         0.        ]\n",
      " [0.         0.         0.         0.         1.56427143 0.\n",
      "  0.         1.56427143 0.         0.        ]\n",
      " [0.         0.         0.         0.         1.74036269 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         1.74036269\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         1.74036269\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  1.74036269 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  1.74036269 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         1.74036269 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         1.74036269 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.74036269 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.74036269 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.74036269 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         1.74036269]]\n"
     ]
    }
   ],
   "source": [
    "#Term - Document Matrix\n",
    "TD = np.zeros((len(vocab),len(doc_dict)))\n",
    "for word in vocab:\n",
    "    for doc_id, doc in tf_idf.items():\n",
    "        ind1 = vocab.index(word)\n",
    "        ind2 = list(tf_idf.keys()).index(doc_id)\n",
    "        TD[ind1][ind2] = tf_idf[doc_id][word]\n",
    "print(TD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38aea075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n",
      " [1.1383027 ]\n",
      " [1.43933269]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [1.74036269]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Term - Query Matrix\n",
    "TQ = np.zeros((len(vocab), 1)) #hanya 1 query\n",
    "for word in vocab:\n",
    "    ind1 = vocab.index(word)\n",
    "    TQ[ind1][0] = tf_query[word]*idf[word]\n",
    "print(TQ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39631c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def cosine_sim(vec1,vec2):\n",
    "    vec1 = list(vec1)\n",
    "    vec2 = list(vec2)\n",
    "    dot_prod = 0\n",
    "    for i, v in enumerate(vec1):\n",
    "        dot_prod += v * vec2[i]\n",
    "    mag_1 = math.sqrt(sum([x**2 for x in vec1]))\n",
    "    mag_2 = math.sqrt(sum([x**2 for x in vec2]))\n",
    "    return dot_prod / (mag_1 * mag_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad7ae9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.480079152100338\n",
      "0.0\n",
      "0.16932053623985205\n",
      "0.41815389455319024\n",
      "0.16089978667393964\n",
      "0.16932053623985205\n",
      "0.7724111379389828\n",
      "0.1392173194695625\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(cosine_sim(TQ[:, 0], TD[:, 0])) #query & doc1\n",
    "print(cosine_sim(TQ[:, 0], TD[:, 1])) #query & doc2\n",
    "print(cosine_sim(TQ[:, 0], TD[:, 2])) #query & doc3\n",
    "print(cosine_sim(TQ[:, 0], TD[:, 3]))\n",
    "print(cosine_sim(TQ[:, 0], TD[:, 4]))\n",
    "print(cosine_sim(TQ[:, 0], TD[:, 5]))\n",
    "print(cosine_sim(TQ[:, 0], TD[:, 6]))\n",
    "print(cosine_sim(TQ[:, 0], TD[:, 7]))\n",
    "print(cosine_sim(TQ[:, 0], TD[:, 8]))\n",
    "print(cosine_sim(TQ[:, 0], TD[:, 9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5daf1450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def exact_top_k(doc_dict, TD, q, k):\n",
    "    relevance_scores = {}\n",
    "    i = 0\n",
    "    for doc_id in doc_dict.keys():\n",
    "        relevance_scores[doc_id] = cosine_sim(q, TD[:, i])\n",
    "        i = i + 1\n",
    "        \n",
    "    sorted_value = OrderedDict(sorted(relevance_scores.items(), key=lambda x: x[1], reverse = True))\n",
    "    top_k = {j: sorted_value[j] for j in list(sorted_value)[:k]}\n",
    "    return top_k\n",
    "top_2 = exact_top_k(doc_dict, TD, TQ[:, 0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e233ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc7': 0.7724111379389828, 'doc1': 0.480079152100338, 'doc4': 0.41815389455319024}\n"
     ]
    }
   ],
   "source": [
    "top_3 = exact_top_k(doc_dict, TD, TQ[:, 0], 3)\n",
    "print(top_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4692f7",
   "metadata": {},
   "source": [
    "#### Precision, Recall, dan F-Measure Top-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93aac5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 60.0 75.0\n"
     ]
    }
   ],
   "source": [
    "top_3 = {'doc7': 0.7689768599816609, 'doc1': 0.4641504133851462, 'doc4': 0.35626622628022314}\n",
    "rel_judgement1 = {'doc1':1, 'doc2':0, 'doc3':0, 'doc4':1, 'doc5':1, 'doc6':0, 'doc7':1, 'doc8':1, 'doc9':0, 'doc10':0}\n",
    "rel_docs = [] #list untuk doc yg relevant\n",
    "for doc_id, rel in rel_judgement1.items():\n",
    "    if rel==1:\n",
    "        rel_docs.append(doc_id)\n",
    "        \n",
    "retrieved_rel_doc3 = [value for value in list(top_3.keys()) if value in rel_docs]\n",
    "prec3 = len(retrieved_rel_doc3)/len(top_3)*100 #3/3\n",
    "rec3 = len(retrieved_rel_doc3)/len(rel_docs)*100 #3/5\n",
    "fScore3 = 2 * prec3 * rec3 / (prec3 + rec3)\n",
    "print(prec3, rec3, fScore3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a459b56e",
   "metadata": {},
   "source": [
    "#### Precision, Recall, F-Measure Top-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d1f3e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.0 60.0 60.0\n"
     ]
    }
   ],
   "source": [
    "top_5 = {'doc7': 0.7689768599816609, 'doc1': 0.4641504133851462, 'doc4': 0.35626622628022314, 'doc3': 0.10856998991379904, 'doc6': 0.10856998991379904}\n",
    "rel_judgement1 = {'doc1':1, 'doc2':0, 'doc3':0, 'doc4':1, 'doc5':1, 'doc6':0, 'doc7':1, 'doc8':1, 'doc9':0, 'doc10':0}\n",
    "rel_docs = []\n",
    "for doc_id, rel in rel_judgement1.items():\n",
    "    if rel==1:\n",
    "        rel_docs.append(doc_id)\n",
    "retrieved_rel_doc5 = [value for value in list(top_5.keys()) if value in rel_docs]\n",
    "prec5 = len(retrieved_rel_doc5)/len(top_5)*100 #3/5\n",
    "rec5 = len(retrieved_rel_doc5)/len(rel_docs)*100 #3/5\n",
    "fScore5 = 2 * prec5 * rec5 / (prec5 + rec5)\n",
    "print(prec5, rec5, fScore5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd02053",
   "metadata": {},
   "source": [
    "### Evaluasi untuk Ranked Retrieval Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d443110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_prf_metrics(I, score, I_Q):\n",
    "    \"\"\"Compute precision, recall, F-measures and other\n",
    "    evaluation metrics for document-level retrieval\n",
    "\n",
    "    Args:\n",
    "        I (np.ndarray): Array of items\n",
    "        score (np.ndarray): Array containing the score values of the times\n",
    "        I_Q (np.ndarray): Array of relevant (positive) items\n",
    "\n",
    "    Returns:\n",
    "        P_Q (float): Precision\n",
    "        R_Q (float): Recall\n",
    "        F_Q (float): F-measures sorted by rank\n",
    "        BEP (float): Break-even point\n",
    "        F_max (float): Maximal F-measure\n",
    "        P_average (float): Mean average\n",
    "        X_Q (np.ndarray): Relevance function\n",
    "        rank (np.ndarray): Array of rank values\n",
    "        I_sorted (np.ndarray): Array of items sorted by rank\n",
    "        rank_sorted (np.ndarray): Array of rank values sorted by rank\n",
    "        \"\"\"\n",
    "    # Compute rank and sort documents according to rank\n",
    "    K = len(I)\n",
    "    index_sorted = np.flip(np.argsort(score))\n",
    "    I_sorted = I[index_sorted]\n",
    "    rank = np.argsort(index_sorted) + 1\n",
    "    rank_sorted = np.arange(1, K+1)\n",
    " \n",
    "    # Compute relevance function X_Q (indexing starts with zero)\n",
    "    X_Q = np.isin(I_sorted, I_Q)\n",
    "\n",
    "    # Compute precision and recall values (indexing starts with zero)\n",
    "    M = len(I_Q)\n",
    "    P_Q = np.cumsum(X_Q) / np.arange(1, K+1)\n",
    "    R_Q = np.cumsum(X_Q) / M\n",
    "    \n",
    "    # Break-even point\n",
    "    BEP = P_Q[M-1]\n",
    "    # Maximal F-measure\n",
    "    sum_PR = P_Q + R_Q\n",
    "    sum_PR[sum_PR == 0] = 1 # Avoid division by zero\n",
    "    F_Q = 2 * (P_Q * R_Q) / sum_PR\n",
    "    F_max = F_Q.max()\n",
    "    # Average precision\n",
    "    P_average = np.sum(P_Q * X_Q) / len(I_Q)\n",
    "    \n",
    "    return P_Q, R_Q, F_Q, BEP, F_max, P_average, X_Q, rank, I_sorted, rank_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba6b5e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank     ID     Score  $\\chi_\\mathcal{Q}$      P(r)  R(r)      F(r)\n",
      "0     1   doc7  0.768977                True  1.000000   0.2  0.333333\n",
      "1     2   doc1  0.464150                True  1.000000   0.4  0.571429\n",
      "2     3   doc4  0.356266                True  1.000000   0.6  0.750000\n",
      "3     4   doc6  0.108570               False  0.750000   0.6  0.666667\n",
      "4     5   doc3  0.108570               False  0.600000   0.6  0.600000\n",
      "5     6   doc5  0.107056                True  0.666667   0.8  0.727273\n",
      "6     7   doc8  0.089678                True  0.714286   1.0  0.833333\n",
      "7     8  doc10  0.000000               False  0.625000   1.0  0.769231\n",
      "8     9   doc9  0.000000               False  0.555556   1.0  0.714286\n",
      "9    10   doc2  0.000000               False  0.500000   1.0  0.666667\n",
      "Break-even point = 0.60\n",
      "F_max = 0.83\n",
      "Average precision = 0.87619\n"
     ]
    }
   ],
   "source": [
    "relevance_score1 = {'doc1': 0.4641504133851462, 'doc2': 0.0, 'doc3': 0.10856998991379904, 'doc4': 0.35626622628022314, 'doc5': 0.10705617011820337, 'doc6': 0.10856998991379904,'doc7': 0.7689768599816609, 'doc8': 0.08967792817935699, 'doc9': 0.0, 'doc10': 0.0}\n",
    "I = np.array(list(relevance_score1.keys()))\n",
    "score = np.array(list(relevance_score1.values()))\n",
    "I_Q = np.array(['doc1', 'doc4', 'doc5', 'doc7', 'doc8'])\n",
    "output = compute_prf_metrics(I, score, I_Q)\n",
    "P_Q, R_Q, F_Q, BEP, F_max, P_average, X_Q, rank, I_sorted, rank_sorted = output\n",
    "\n",
    "# Arrange output as tables\n",
    "score_sorted = np.flip(np.sort(score))\n",
    "import pandas as pd \n",
    "df = pd.DataFrame({'Rank': rank_sorted, 'ID': I_sorted,'Score': score_sorted,'$\\chi_\\mathcal{Q}$': X_Q, 'P(r)': P_Q, 'R(r)': R_Q,'F(r)': F_Q})\n",
    "print(df)\n",
    "\n",
    "print('Break-even point = %.2f' % BEP)\n",
    "print('F_max = %.2f' % F_max)\n",
    "print('Average precision =', np.round(P_average, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f00c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_PR_curve(P_Q, R_Q, figsize=(3, 3)):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    plt.plot(R_Q, P_Q, linestyle='--', marker='o', color='k', mfc='r')\n",
    "    plt.xlim([0, 1.1])\n",
    "    plt.ylim([0, 1.1])\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    plt.title('PR curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    ax.plot(BEP, BEP, color='green', marker='o', fillstyle='none', markersize=15)\n",
    "    ax.set_title('PR curve')\n",
    "    plt.show() \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab36c92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Figure size 216x216 with 1 Axes>,\n",
       " <AxesSubplot:title={'center':'PR curve'}, xlabel='Recall', ylabel='Precision'>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_PR_curve(P_Q, R_Q, figsize=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceec098b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semoga jago IR\n",
      "AAAMIIIN\n"
     ]
    }
   ],
   "source": [
    "print(\"semoga jago IR\")\n",
    "print(\"AAAMIIIN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
