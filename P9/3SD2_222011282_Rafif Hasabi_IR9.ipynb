{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bc4aa69",
   "metadata": {},
   "source": [
    "# PENUGASAN PRAKTIKUM _INFORMATION RETRIEVAL_ PERTEMUAN 9\n",
    "\n",
    "NAMA &emsp;&emsp;&emsp;: RAFIF HASABI </br>\n",
    "NIM  &emsp;&emsp;&emsp;&emsp;: 222011282 </br>\n",
    "KELAS &emsp; &emsp; : 3SD2 </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038899ab",
   "metadata": {},
   "source": [
    "Data yang digunakan pada praktikum _Information Retrieval_ pertemuan ke-9 adalah data pada folder berita yang terdiri dari 5 buah file. Perintah dalam penugasan ini adalah sebagai berikut.\n",
    "\n",
    "1. Buat fungsi untuk menampilkan 3 list dokumen yang terurut pada folder ”berita” dengan query ”vaksin corona jakarta”, berdasarkan standar query likelihood model serta query likelihood model dengan Laplace Smoothing, Jelinek-Mercer Smoothing, dan Dirichlet Smoothing. Bandingkan dengan hasil perankingan BM25 pada modul 8 serta cosine similarity pada modul 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a52706",
   "metadata": {},
   "source": [
    "## 1. PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbef3c5",
   "metadata": {},
   "source": [
    "Sebelum dilakukan preprocessing terhadap data yang dimiliki. Terlebih dahulu kita import datanya menggunakan module os. Kemudian dikarenakan pada file terdapat beberapa karakter yang perlu dihapus misalkan saja __\"\\n\\n\"__ dan __\"https\\\"__ maka ditambahkan pula kode untuk menghapus karakter tersebut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "208907c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Module\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lang.id.stop_words import STOP_WORDS\n",
    "from spacy.lang.id import Indonesian\n",
    "\n",
    "nlp = spacy.blank('id')\n",
    "\n",
    "# Folder Path\n",
    "path = r\"C:\\Users\\HP\\OneDrive - Universitas Diponegoro\\Documents\\Kuliah STIS V\\Information Retrieval\\Praktik\\berita\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b9a1c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inisiasikan objek list_file untuk menyimpan dokumen nantinya dengan append\n",
    "list_file = []\n",
    "\n",
    "for file in os.listdir(path): \n",
    "    if os.path.isfile(os.path.join(path, file)):\n",
    "        file_path=f\"{path}\\{file}\"\n",
    "        with open(file_path,'r') as t:\n",
    "            list_file.append(t.read().lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3a83be",
   "metadata": {},
   "source": [
    "### 1.1. Case Folding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc5b47",
   "metadata": {},
   "source": [
    "Teknik preprocessing yang pertama dilakukan adalah merubah seluruh teks menjadi lower case agar mempermudah dalam melakukan analisis selanjutnya.\n",
    "Untuk case Folding sendiri telah dilakukan pada saat melakukan _import_ file, yaitu pada sintaks __list_file.append(t.read().lower()__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8a3c91",
   "metadata": {},
   "source": [
    "### 1.2. Tokenisasi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e62b112",
   "metadata": {},
   "source": [
    "Tokenisasi adalah proses memotong suatu teks menjadi bagian-bagian yang disebut token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "722dc0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenisasi(docs):\n",
    "    hasil_tokenisasi = []\n",
    "    \n",
    "    for doc in docs:    \n",
    "        spacy_id = nlp(doc)\n",
    "        token_kata = [token.text for token in spacy_id]\n",
    "        hasil_tokenisasi.append(token_kata)\n",
    "    return (hasil_tokenisasi)\n",
    "\n",
    "list_file = tokenisasi(list_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c66331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenisasi2(text):\n",
    "    tokens = text.split(\" \")\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8aa8fc",
   "metadata": {},
   "source": [
    "### 1.3. Eliminasi Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92dfb29",
   "metadata": {},
   "source": [
    "Eliminasi Stopwords adalah teknik preprocessing yang dilakukan untuk menghilangkan kata-kata yang dianggap hanya sedikit berarti dalam pemrosesan teks namun seringkali muncul, sehingga dapat dieliminasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b51c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminasiStopword(docs):\n",
    "    hasil = []\n",
    "    hasil_stopwords = []\n",
    "    \n",
    "    for doc in range(len(docs)):\n",
    "        hasil = [w for w in docs[doc] if not w in STOP_WORDS]\n",
    "        hasil_stopwords.append(hasil)\n",
    "    return hasil_stopwords\n",
    "\n",
    "list_file = eliminasiStopword(list_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fbc203",
   "metadata": {},
   "source": [
    "### 1.4. Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f3ed5c",
   "metadata": {},
   "source": [
    "Stemming merupakan teknik preprocessing yang digunakan untuk mengubah suatu kata ke bentuk dasarnya. Dalam bahasa indonesia dapat diartikan bahwa stemming menghilangkan imbuhan-imbuhan pada suatu kata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc1a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def stemming(docs) :\n",
    "    hasil = []\n",
    "    hasil_stemming = []\n",
    "    for doc in docs:\n",
    "        for text in doc :\n",
    "            hasil.append(stemmer.stem(text))\n",
    "        hasil_stemming.append(hasil)\n",
    "        hasil = []\n",
    "    return hasil_stemming\n",
    "\n",
    "list_file = stemming(list_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b44c1a1",
   "metadata": {},
   "source": [
    "### 1.5. Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c46c317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterProcess(docs) :\n",
    "    # hilangkan tautan untuk web\n",
    "    docs = re.sub(r\"\\S*https?:\\S*\", '', docs) \n",
    "    # hilangkan karakter-karakter yang tidak signifikan\n",
    "    docs = re.sub(r\"[.,:;+!\\-_<^/=?\\\"'\\(\\)\\d\\*]\", \" \", docs)\n",
    "    # hilangkan space\n",
    "    docs = re.sub(r\"[' ']\",\"\",docs)\n",
    "    return docs\n",
    "\n",
    "def filterDoc(docs) :\n",
    "    for doc in range(len(docs)):\n",
    "        d = 0\n",
    "        docs[doc]=[x for x in docs[doc] if x]\n",
    "        docs[doc]=[x for x in docs[doc] if len(x) < 32] #menghapus link\n",
    "        for text in docs[doc]:\n",
    "            docs[doc][d] = filterProcess(text)\n",
    "            d = d + 1\n",
    "    return docs\n",
    "\n",
    "list_file = filterDoc(list_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20fc040",
   "metadata": {},
   "source": [
    "### 1.6. Normalisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542f4ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_word = {\"anter\": \"antar\", \"ap2\": \"apa-apa\", \"apasih\": \"apa sih\", \"apes\": \"sial\", \"aps\": \"apa\", \"aq\": \"saya\", \"aquwh\": \"aku\", \"asbun\": \"asal bunyi\", \"aseekk\": \"asyik\", \"asekk\": \"asyik\", \"asem\": \"asam\", \"aspal\": \"asli tetapi palsu\", \"astul\": \"asal tulis\", \"ato\": \"atau\", \"au ah\": \"tidak mau tahu\", \"awak\": \"saya\", \"ay\": \"sayang\", \"ayank\": \"sayang\", \"b4\": \"sebelum\", \"bakalan\": \"akan\", \"bandes\": \"bantuan desa\", \"bangedh\": \"banget\", \"@\": \"di\", \"abis\": \"habis\", \"ad\": \"ada\", \"adlh\": \"adalah\", \"afaik\": \"as far as i know\", \"ahaha\": \"haha\", \"aj\": \"saja\", \"ajep-ajep\": \"dunia gemerlap\", \"ak\": \"saya\", \"akika\": \"aku\", \"akkoh\": \"aku\", \"akuwh\": \"aku\", \"alay\": \"norak\", \"alow\": \"halo\", \"ambilin\": \"ambilkan\", \"ancur\": \"hancur\", \"anjrit\": \"anjing\", \"banpol\": \"bantuan polisi\", \"banpur\": \"bantuan tempur\", \"basbang\": \"basi\", \"bcanda\": \"bercanda\", \"bdg\": \"bandung\", \"begajulan\": \"nakal\", \"beliin\": \"belikan\", \"bencong\": \"banci\", \"bentar\": \"sebentar\", \"ber3\": \"bertiga\", \"beresin\": \"membereskan\", \"bete\": \"bosan\", \"beud\": \"banget\", \"bg\": \"abang\", \"bgmn\": \"bagaimana\", \"bgt\": \"banget\", \"bijimane\": \"bagaimana\", \"bintal\": \"bimbingan mental\", \"bkl\": \"akan\", \"bknnya\": \"bukannya\", \"blegug\": \"bodoh\", \"blh\": \"boleh\", \"bln\": \"bulan\", \"blum\": \"belum\", \"bnci\": \"benci\", \"bnran\": \"yang benar\", \"bodor\": \"lucu\", \"bokap\": \"ayah\", \"boker\": \"buang air besar\", \"bokis\": \"bohong\", \"boljug\": \"boleh juga\", \"bonek\": \"bocah nekat\", \"boyeh\": \"boleh\", \"br\": \"baru\", \"brg\": \"bareng\", \"bro\": \"saudara laki-laki\", \"bru\": \"baru\", \"bs\": \"bisa\", \"bsen\": \"bosan\", \"bt\": \"buat\", \"btw\": \"ngomong-ngomong\", \"buaya\": \"tidak setia\", \"bubbu\": \"tidur\", \"bubu\": \"tidur\", \"bumil\": \"ibu hamil\", \"bw\": \"bawa\", \"bwt\": \"buat\", \"byk\": \"banyak\", \"byrin\": \"bayarkan\", \"cabal\": \"sabar\", \"cadas\": \"keren\", \"calo\": \"makelar\", \"can\": \"belum\", \"capcus\": \"pergi\", \"caper\": \"cari perhatian\", \"ce\": \"cewek\", \"cekal\": \"cegah tangkal\", \"cemen\": \"penakut\", \"cengengesan\": \"tertawa\", \"cepet\": \"cepat\", \"cew\": \"cewek\", \"chuyunk\": \"sayang\", \"cimeng\": \"ganja\", \"cipika cipiki\": \"cium pipi kanan cium pipi kiri\", \"ciyh\": \"sih\", \"ckepp\": \"cakep\", \"ckp\": \"cakep\", \"cmiiw\": \"correct me if i'm wrong\", \"cmpur\": \"campur\", \"cong\": \"banci\", \"conlok\": \"cinta lokasi\", \"cowwyy\": \"maaf\", \"cp\": \"siapa\", \"cpe\": \"capek\", \"cppe\": \"capek\", \"cucok\": \"cocok\", \"cuex\": \"cuek\", \"cumi\": \"Cuma miscall\", \"cups\": \"culun\", \"curanmor\": \"pencurian kendaraan bermotor\", \"curcol\": \"curahan hati colongan\", \"cwek\": \"cewek\", \"cyin\": \"cinta\", \"d\": \"di\", \"dah\": \"deh\", \"dapet\": \"dapat\", \"de\": \"adik\", \"dek\": \"adik\", \"demen\": \"suka\", \"deyh\": \"deh\", \"dgn\": \"dengan\", \"diancurin\": \"dihancurkan\", \"dimaafin\": \"dimaafkan\", \"dimintak\": \"diminta\", \"disono\": \"di sana\", \"dket\": \"dekat\", \"dkk\": \"dan kawan-kawan\", \"dll\": \"dan lain-lain\", \"dlu\": \"dulu\", \"dngn\": \"dengan\", \"dodol\": \"bodoh\", \"doku\": \"uang\", \"dongs\": \"dong\", \"dpt\": \"dapat\", \"dri\": \"dari\", \"drmn\": \"darimana\", \"drtd\": \"dari tadi\", \"dst\": \"dan seterusnya\", \"dtg\": \"datang\", \"duh\": \"aduh\", \"duren\": \"durian\", \"ed\": \"edisi\", \"egp\": \"emang gue pikirin\", \"eke\": \"aku\", \"elu\": \"kamu\", \"emangnya\": \"memangnya\", \"emng\": \"memang\", \"endak\": \"tidak\", \"enggak\": \"tidak\", \"envy\": \"iri\", \"ex\": \"mantan\", \"fax\": \"facsimile\", \"fifo\": \"first in first out\", \"folbek\": \"follow back\", \"fyi\": \"sebagai informasi\", \"gaada\": \"tidak ada uang\", \"gag\": \"tidak\", \"gaje\": \"tidak jelas\", \"gak papa\": \"tidak apa-apa\", \"gan\": \"juragan\", \"gaptek\": \"gagap teknologi\", \"gatek\": \"gagap teknologi\", \"gawe\": \"kerja\", \"gbs\": \"tidak bisa\", \"gebetan\": \"orang yang disuka\", \"geje\": \"tidak jelas\", \"gepeng\": \"gelandangan dan pengemis\", \"ghiy\": \"lagi\", \"gile\": \"gila\", \"gimana\": \"bagaimana\", \"gino\": \"gigi nongol\", \"githu\": \"gitu\", \"gj\": \"tidak jelas\", \"gmana\": \"bagaimana\", \"gn\": \"begini\", \"goblok\": \"bodoh\", \"golput\": \"golongan putih\", \"gowes\": \"mengayuh sepeda\", \"gpny\": \"tidak punya\", \"gr\": \"gede rasa\", \"gretongan\": \"gratisan\", \"gtau\": \"tidak tahu\", \"gua\": \"saya\", \"guoblok\": \"goblok\", \"gw\": \"saya\", \"ha\": \"tertawa\", \"haha\": \"tertawa\", \"hallow\": \"halo\", \"hankam\": \"pertahanan dan keamanan\", \"hehe\": \"he\", \"helo\": \"halo\", \"hey\": \"hai\", \"hlm\": \"halaman\", \"hny\": \"hanya\", \"hoax\": \"isu bohong\", \"hr\": \"hari\", \"hrus\": \"harus\", \"hubdar\": \"perhubungan darat\", \"huff\": \"mengeluh\", \"hum\": \"rumah\", \"humz\": \"rumah\", \"ilang\": \"hilang\", \"ilfil\": \"tidak suka\", \"imho\": \"in my humble opinion\", \"imoetz\": \"imut\", \"item\": \"hitam\", \"itungan\": \"hitungan\", \"iye\": \"iya\", \"ja\": \"saja\", \"jadiin\": \"jadi\", \"jaim\": \"jaga image\", \"jayus\": \"tidak lucu\", \"jdi\": \"jadi\", \"jem\": \"jam\", \"jga\": \"juga\", \"jgnkan\": \"jangankan\", \"jir\": \"anjing\", \"jln\": \"jalan\", \"jomblo\": \"tidak punya pacar\", \"jubir\": \"juru bicara\", \"jutek\": \"galak\", \"k\": \"ke\", \"kab\": \"kabupaten\", \"kabor\": \"kabur\", \"kacrut\": \"kacau\", \"kadiv\": \"kepala divisi\", \"kagak\": \"tidak\", \"kalo\": \"kalau\", \"kampret\": \"sialan\", \"kamtibmas\": \"keamanan dan ketertiban masyarakat\", \"kamuwh\": \"kamu\", \"kanwil\": \"kantor wilayah\", \"karna\": \"karena\", \"kasubbag\": \"kepala subbagian\", \"katrok\": \"kampungan\", \"kayanya\": \"kayaknya\", \"kbr\": \"kabar\", \"kdu\": \"harus\", \"kec\": \"kecamatan\", \"kejurnas\": \"kejuaraan nasional\", \"kekeuh\": \"keras kepala\", \"kel\": \"kelurahan\", \"kemaren\": \"kemarin\", \"kepengen\": \"mau\", \"kepingin\": \"mau\", \"kepsek\": \"kepala sekolah\", \"kesbang\": \"kesatuan bangsa\", \"kesra\": \"kesejahteraan rakyat\", \"ketrima\": \"diterima\", \"kgiatan\": \"kegiatan\", \"kibul\": \"bohong\", \"kimpoi\": \"kawin\", \"kl\": \"kalau\", \"klianz\": \"kalian\", \"kloter\": \"kelompok terbang\", \"klw\": \"kalau\", \"km\": \"kamu\", \"kmps\": \"kampus\", \"kmrn\": \"kemarin\", \"knal\": \"kenal\", \"knp\": \"kenapa\", \"kodya\": \"kota madya\", \"komdis\": \"komisi disiplin\", \"komsov\": \"komunis sovyet\", \"kongkow\": \"kumpul bareng teman-teman\", \"kopdar\": \"kopi darat\", \"korup\": \"korupsi\", \"kpn\": \"kapan\", \"krenz\": \"keren\", \"krm\": \"kirim\", \"kt\": \"kita\", \"ktmu\": \"ketemu\", \"ktr\": \"kantor\", \"kuper\": \"kurang pergaulan\", \"kw\": \"imitasi\", \"kyk\": \"seperti\", \"la\": \"lah\", \"lam\": \"salam\", \"lamp\": \"lampiran\", \"lanud\": \"landasan udara\", \"latgab\": \"latihan gabungan\", \"lebay\": \"berlebihan\", \"leh\": \"boleh\", \"lelet\": \"lambat\", \"lemot\": \"lambat\", \"lgi\": \"lagi\", \"lgsg\": \"langsung\", \"liat\": \"lihat\", \"litbang\": \"penelitian dan pengembangan\", \"lmyn\": \"lumayan\", \"lo\": \"kamu\", \"loe\": \"kamu\", \"lola\": \"lambat berfikir\", \"louph\": \"cinta\", \"low\": \"kalau\", \"lp\": \"lupa\", \"luber\": \"langsung, umum, bebas, dan rahasia\", \"luchuw\": \"lucu\", \"lum\": \"belum\", \"luthu\": \"lucu\", \"lwn\": \"lawan\", \"maacih\": \"terima kasih\", \"mabal\": \"bolos\", \"macem\": \"macam\", \"macih\": \"masih\", \"maem\": \"makan\", \"magabut\": \"makan gaji buta\", \"maho\": \"homo\", \"mak jang\": \"kaget\", \"maksain\": \"memaksa\", \"malem\": \"malam\", \"mam\": \"makan\", \"maneh\": \"kamu\", \"maniez\": \"manis\", \"mao\": \"mau\", \"masukin\": \"masukkan\", \"melu\": \"ikut\", \"mepet\": \"dekat sekali\", \"mgu\": \"minggu\", \"migas\": \"minyak dan gas bumi\", \"mikol\": \"minuman beralkohol\", \"miras\": \"minuman keras\", \"mlah\": \"malah\", \"mngkn\": \"mungkin\", \"mo\": \"mau\", \"mokad\": \"mati\", \"moso\": \"masa\", \"mpe\": \"sampai\", \"msk\": \"masuk\", \"mslh\": \"masalah\", \"mt\": \"makan teman\", \"mubes\": \"musyawarah besar\", \"mulu\": \"melulu\", \"mumpung\": \"selagi\", \"munas\": \"musyawarah nasional\", \"muntaber\": \"muntah dan berak\", \"musti\": \"mesti\", \"muupz\": \"maaf\", \"mw\": \"now watching\", \"n\": \"dan\", \"nanam\": \"menanam\", \"nanya\": \"bertanya\", \"napa\": \"kenapa\", \"napi\": \"narapidana\", \"napza\": \"narkotika, alkohol, psikotropika, dan zat adiktif \", \"narkoba\": \"narkotika, psikotropika, dan obat terlarang\", \"nasgor\": \"nasi goreng\", \"nda\": \"tidak\", \"ndiri\": \"sendiri\", \"ne\": \"ini\", \"nekolin\": \"neokolonialisme\", \"nembak\": \"menyatakan cinta\", \"ngabuburit\": \"menunggu berbuka puasa\", \"ngaku\": \"mengaku\", \"ngambil\": \"mengambil\", \"nganggur\": \"tidak punya pekerjaan\", \"ngapah\": \"kenapa\", \"ngaret\": \"terlambat\", \"ngasih\": \"memberikan\", \"ngebandel\": \"berbuat bandel\", \"ngegosip\": \"bergosip\", \"ngeklaim\": \"mengklaim\", \"ngeksis\": \"menjadi eksis\", \"ngeles\": \"berkilah\", \"ngelidur\": \"menggigau\", \"ngerampok\": \"merampok\", \"ngga\": \"tidak\", \"ngibul\": \"berbohong\", \"ngiler\": \"mau\", \"ngiri\": \"iri\", \"ngisiin\": \"mengisikan\", \"ngmng\": \"bicara\", \"ngomong\": \"bicara\", \"ngubek2\": \"mencari-cari\", \"ngurus\": \"mengurus\", \"nie\": \"ini\", \"nih\": \"ini\", \"niyh\": \"nih\", \"nmr\": \"nomor\", \"nntn\": \"nonton\", \"nobar\": \"nonton bareng\", \"np\": \"now playing\", \"ntar\": \"nanti\", \"ntn\": \"nonton\", \"numpuk\": \"bertumpuk\", \"nutupin\": \"menutupi\", \"nyari\": \"mencari\", \"nyekar\": \"menyekar\", \"nyicil\": \"mencicil\", \"nyoblos\": \"mencoblos\", \"nyokap\": \"ibu\", \"ogah\": \"tidak mau\", \"ol\": \"online\", \"ongkir\": \"ongkos kirim\", \"oot\": \"out of topic\", \"org2\": \"orang-orang\", \"ortu\": \"orang tua\", \"otda\": \"otonomi daerah\", \"otw\": \"on the way, sedang di jalan\", \"pacal\": \"pacar\", \"pake\": \"pakai\", \"pala\": \"kepala\", \"pansus\": \"panitia khusus\", \"parpol\": \"partai politik\", \"pasutri\": \"pasangan suami istri\", \"pd\": \"pada\", \"pede\": \"percaya diri\", \"pelatnas\": \"pemusatan latihan nasional\", \"pemda\": \"pemerintah daerah\", \"pemkot\": \"pemerintah kota\", \"pemred\": \"pemimpin redaksi\", \"penjas\": \"pendidikan jasmani\", \"perda\": \"peraturan daerah\", \"perhatiin\": \"perhatikan\", \"pesenan\": \"pesanan\", \"pgang\": \"pegang\", \"pi\": \"tapi\", \"pilkada\": \"pemilihan kepala daerah\", \"pisan\": \"sangat\", \"pk\": \"penjahat kelamin\", \"plg\": \"paling\", \"pmrnth\": \"pemerintah\", \"polantas\": \"polisi lalu lintas\", \"ponpes\": \"pondok pesantren\", \"pp\": \"pulang pergi\", \"prg\": \"pergi\", \"prnh\": \"pernah\", \"psen\": \"pesan\", \"pst\": \"pasti\", \"pswt\": \"pesawat\", \"pw\": \"posisi nyaman\", \"qmu\": \"kamu\", \"rakor\": \"rapat koordinasi\", \"ranmor\": \"kendaraan bermotor\", \"re\": \"reply\", \"ref\": \"referensi\", \"rehab\": \"rehabilitasi\", \"rempong\": \"sulit\", \"repp\": \"balas\", \"restik\": \"reserse narkotika\", \"rhs\": \"rahasia\", \"rmh\": \"rumah\", \"ru\": \"baru\", \"ruko\": \"rumah toko\", \"rusunawa\": \"rumah susun sewa\", \"ruz\": \"terus\", \"saia\": \"saya\", \"salting\": \"salah tingkah\", \"sampe\": \"sampai\", \"samsek\": \"sama sekali\", \"sapose\": \"siapa\", \"satpam\": \"satuan pengamanan\", \"sbb\": \"sebagai berikut\", \"sbh\": \"sebuah\", \"sbnrny\": \"sebenarnya\", \"scr\": \"secara\", \"sdgkn\": \"sedangkan\", \"sdkt\": \"sedikit\", \"se7\": \"setuju\", \"sebelas dua belas\": \"mirip\", \"sembako\": \"sembilan bahan pokok\", \"sempet\": \"sempat\", \"sendratari\": \"seni drama tari\", \"sgt\": \"sangat\", \"shg\": \"sehingga\", \"siech\": \"sih\", \"sikon\": \"situasi dan kondisi\", \"sinetron\": \"sinema elektronik\", \"siramin\": \"siramkan\", \"sj\": \"saja\", \"skalian\": \"sekalian\", \"sklh\": \"sekolah\", \"skt\": \"sakit\", \"slesai\": \"selesai\", \"sll\": \"selalu\", \"slma\": \"selama\", \"slsai\": \"selesai\", \"smpt\": \"sempat\", \"smw\": \"semua\", \"sndiri\": \"sendiri\", \"soljum\": \"sholat jumat\", \"songong\": \"sombong\", \"sory\": \"maaf\", \"sosek\": \"sosial-ekonomi\", \"sotoy\": \"sok tahu\", \"spa\": \"siapa\", \"sppa\": \"siapa\", \"spt\": \"seperti\", \"srtfkt\": \"sertifikat\", \"stiap\": \"setiap\", \"stlh\": \"setelah\", \"suk\": \"masuk\", \"sumpek\": \"sempit\", \"syg\": \"sayang\", \"t4\": \"tempat\", \"tajir\": \"kaya\", \"tau\": \"tahu\", \"taw\": \"tahu\", \"td\": \"tadi\", \"tdk\": \"tidak\", \"teh\": \"kakak perempuan\", \"telat\": \"terlambat\", \"telmi\": \"telat berpikir\", \"temen\": \"teman\", \"tengil\": \"menyebalkan\", \"tepar\": \"terkapar\", \"tggu\": \"tunggu\", \"tgu\": \"tunggu\", \"thankz\": \"terima kasih\", \"thn\": \"tahun\", \"tilang\": \"bukti pelanggaran\", \"tipiwan\": \"TvOne\", \"tks\": \"terima kasih\", \"tlp\": \"telepon\", \"tls\": \"tulis\", \"tmbah\": \"tambah\", \"tmen2\": \"teman-teman\", \"tmpah\": \"tumpah\", \"tmpt\": \"tempat\", \"tngu\": \"tunggu\", \"tnyta\": \"ternyata\", \"tokai\": \"tai\", \"toserba\": \"toko serba ada\", \"tpi\": \"tapi\", \"trdhulu\": \"terdahulu\", \"trima\": \"terima kasih\", \"trm\": \"terima\", \"trs\": \"terus\", \"trutama\": \"terutama\", \"ts\": \"penulis\", \"tst\": \"tahu sama tahu\", \"ttg\": \"tentang\", \"tuch\": \"tuh\", \"tuir\": \"tua\", \"tw\": \"tahu\", \"u\": \"kamu\", \"ud\": \"sudah\", \"udah\": \"sudah\", \"ujg\": \"ujung\", \"ul\": \"ulangan\", \"unyu\": \"lucu\", \"uplot\": \"unggah\", \"urang\": \"saya\", \"usah\": \"perlu\", \"utk\": \"untuk\", \"valas\": \"valuta asing\", \"w/\": \"dengan\", \"wadir\": \"wakil direktur\", \"wamil\": \"wajib militer\", \"warkop\": \"warung kopi\", \"warteg\": \"warung tegal\", \"wat\": \"buat\", \"wkt\": \"waktu\", \"wtf\": \"what the fuck\", \"xixixi\": \"tertawa\", \"ya\": \"iya\", \"yap\": \"iya\", \"yaudah\": \"ya sudah\", \"yawdah\": \"ya sudah\", \"yg\": \"yang\", \"yl\": \"yang lain\", \"yo\": \"iya\", \"yowes\": \"ya sudah\", \"yup\": \"iya\", \"7an\": \"tujuan\", \"ababil\": \"abg labil\", \"acc\": \"accord\", \"adlah\": \"adalah\", \"adoh\": \"aduh\", \"aha\": \"tertawa\", \"aing\": \"saya\", \"aja\": \"saja\", \"ajj\": \"saja\", \"aka\": \"dikenal juga sebagai\", \"akko\": \"aku\", \"akku\": \"aku\", \"akyu\": \"aku\", \"aljasa\": \"asal jadi saja\", \"ama\": \"sama\", \"ambl\": \"ambil\", \"anjir\": \"anjing\", \"ank\": \"anak\", \"ap\": \"apa\", \"apaan\": \"apa\", \"ape\": \"apa\", \"aplot\": \"unggah\", \"apva\": \"apa\", \"aqu\": \"aku\", \"asap\": \"sesegera mungkin\", \"aseek\": \"asyik\", \"asek\": \"asyik\", \"aseknya\": \"asyiknya\", \"asoy\": \"asyik\", \"astrojim\": \"astagfirullahaladzim\", \"ath\": \"kalau begitu\", \"atuh\": \"kalau begitu\", \"ava\": \"avatar\", \"aws\": \"awas\", \"ayang\": \"sayang\", \"ayok\": \"ayo\", \"bacot\": \"banyak bicara\", \"bales\": \"balas\", \"bangdes\": \"pembangunan desa\", \"bangkotan\": \"tua\", \"banpres\": \"bantuan presiden\", \"bansarkas\": \"bantuan sarana kesehatan\", \"bazis\": \"badan amal, zakat, infak, dan sedekah\", \"bcoz\": \"karena\", \"beb\": \"sayang\", \"bejibun\": \"banyak\", \"belom\": \"belum\", \"bener\": \"benar\", \"ber2\": \"berdua\", \"berdikari\": \"berdiri di atas kaki sendiri\", \"bet\": \"banget\", \"beti\": \"beda tipis\", \"beut\": \"banget\", \"bgd\": \"banget\", \"bgs\": \"bagus\", \"bhubu\": \"tidur\", \"bimbuluh\": \"bimbingan dan penyuluhan\", \"bisi\": \"kalau-kalau\", \"bkn\": \"bukan\", \"bl\": \"beli\", \"blg\": \"bilang\", \"blm\": \"belum\", \"bls\": \"balas\", \"bnchi\": \"benci\", \"bngung\": \"bingung\", \"bnyk\": \"banyak\", \"bohay\": \"badan aduhai\", \"bokep\": \"porno\", \"bokin\": \"pacar\", \"bole\": \"boleh\", \"bolot\": \"bodoh\", \"bonyok\": \"ayah ibu\", \"bpk\": \"bapak\", \"brb\": \"segera kembali\", \"brngkt\": \"berangkat\", \"brp\": \"berapa\", \"brur\": \"saudara laki-laki\", \"bsa\": \"bisa\", \"bsk\": \"besok\", \"bu_bu\": \"tidur\", \"bubarin\": \"bubarkan\", \"buber\": \"buka bersama\", \"bujubune\": \"luar biasa\", \"buser\": \"buru sergap\", \"bwhn\": \"bawahan\", \"byar\": \"bayar\", \"byr\": \"bayar\", \"c8\": \"chat\", \"cabut\": \"pergi\", \"caem\": \"cakep\", \"cama-cama\": \"sama-sama\", \"cangcut\": \"celana dalam\", \"cape\": \"capek\", \"caur\": \"jelek\", \"cekak\": \"tidak ada uang\", \"cekidot\": \"coba lihat\", \"cemplungin\": \"cemplungkan\", \"ceper\": \"pendek\", \"ceu\": \"kakak perempuan\", \"cewe\": \"cewek\", \"cibuk\": \"sibuk\", \"cin\": \"cinta\", \"ciye\": \"cie\", \"ckck\": \"ck\", \"clbk\": \"cinta lama bersemi kembali\", \"cmpr\": \"campur\", \"cnenk\": \"senang\", \"congor\": \"mulut\", \"cow\": \"cowok\", \"coz\": \"karena\", \"cpa\": \"siapa\", \"gokil\": \"gila\", \"gombal\": \"suka merayu\", \"gpl\": \"tidak pakai lama\", \"gpp\": \"tidak apa-apa\", \"gretong\": \"gratis\", \"gt\": \"begitu\", \"gtw\": \"tidak tahu\", \"gue\": \"saya\", \"guys\": \"teman-teman\", \"gws\": \"cepat sembuh\", \"haghaghag\": \"tertawa\", \"hakhak\": \"tertawa\", \"handak\": \"bahan peledak\", \"hansip\": \"pertahanan sipil\", \"hellow\": \"halo\", \"helow\": \"halo\", \"hi\": \"hai\", \"hlng\": \"hilang\", \"hnya\": \"hanya\", \"houm\": \"rumah\", \"hrs\": \"harus\", \"hubad\": \"hubungan angkatan darat\", \"hubla\": \"perhubungan laut\", \"huft\": \"mengeluh\", \"humas\": \"hubungan masyarakat\", \"idk\": \"saya tidak tahu\", \"ilfeel\": \"tidak suka\", \"imba\": \"jago sekali\", \"imoet\": \"imut\", \"info\": \"informasi\", \"itung\": \"hitung\", \"isengin\": \"bercanda\", \"iyala\": \"iya lah\", \"iyo\": \"iya\", \"jablay\": \"jarang dibelai\", \"jadul\": \"jaman dulu\", \"jancuk\": \"anjing\", \"jd\": \"jadi\", \"jdikan\": \"jadikan\", \"jg\": \"juga\", \"jgn\": \"jangan\", \"jijay\": \"jijik\", \"jkt\": \"jakarta\", \"jnj\": \"janji\", \"jth\": \"jatuh\", \"jurdil\": \"jujur adil\", \"jwb\": \"jawab\", \"ka\": \"kakak\", \"kabag\": \"kepala bagian\", \"kacian\": \"kasihan\", \"kadit\": \"kepala direktorat\", \"kaga\": \"tidak\", \"kaka\": \"kakak\", \"kamtib\": \"keamanan dan ketertiban\", \"kamuh\": \"kamu\", \"kamyu\": \"kamu\", \"kapt\": \"kapten\", \"kasat\": \"kepala satuan\", \"kasubbid\": \"kepala subbidang\", \"kau\": \"kamu\", \"kbar\": \"kabar\", \"kcian\": \"kasihan\", \"keburu\": \"terlanjur\", \"kedubes\": \"kedutaan besar\", \"kek\": \"seperti\", \"keknya\": \"kayaknya\", \"keliatan\": \"kelihatan\", \"keneh\": \"masih\", \"kepikiran\": \"terpikirkan\", \"kepo\": \"mau tahu urusan orang\", \"kere\": \"tidak punya uang\", \"kesian\": \"kasihan\", \"ketauan\": \"ketahuan\", \"keukeuh\": \"keras kepala\", \"khan\": \"kan\", \"kibus\": \"kaki busuk\", \"kk\": \"kakak\", \"klian\": \"kalian\", \"klo\": \"kalau\", \"kluarga\": \"keluarga\", \"klwrga\": \"keluarga\", \"kmari\": \"kemari\", \"kmpus\": \"kampus\", \"kn\": \"kan\", \"knl\": \"kenal\", \"knpa\": \"kenapa\", \"kog\": \"kok\", \"kompi\": \"komputer\", \"komtiong\": \"komunis Tiongkok\", \"konjen\": \"konsulat jenderal\", \"koq\": \"kok\", \"kpd\": \"kepada\", \"kptsan\": \"keputusan\", \"krik\": \"garing\", \"krn\": \"karena\", \"ktauan\": \"ketahuan\", \"ktny\": \"katanya\", \"kudu\": \"harus\", \"kuq\": \"kok\", \"ky\": \"seperti\", \"kykny\": \"kayanya\", \"laka\": \"kecelakaan\", \"lambreta\": \"lambat\", \"lansia\": \"lanjut usia\", \"lapas\": \"lembaga pemasyarakatan\", \"lbur\": \"libur\", \"lekong\": \"laki-laki\", \"lg\": \"lagi\", \"lgkp\": \"lengkap\", \"lht\": \"lihat\", \"linmas\": \"perlindungan masyarakat\", \"lmyan\": \"lumayan\", \"lngkp\": \"lengkap\", \"loch\": \"loh\", \"lol\": \"tertawa\", \"lom\": \"belum\", \"loupz\": \"cinta\", \"lowh\": \"kamu\", \"lu\": \"kamu\", \"luchu\": \"lucu\", \"luff\": \"cinta\", \"luph\": \"cinta\", \"lw\": \"kamu\", \"lwt\": \"lewat\", \"maaciw\": \"terima kasih\", \"mabes\": \"markas besar\", \"macem-macem\": \"macam-macam\", \"madesu\": \"masa depan suram\", \"maen\": \"main\", \"mahatma\": \"maju sehat bersama\", \"mak\": \"ibu\", \"makasih\": \"terima kasih\", \"malah\": \"bahkan\", \"malu2in\": \"memalukan\", \"mamz\": \"makan\", \"manies\": \"manis\", \"mantep\": \"mantap\", \"markus\": \"makelar kasus\", \"mba\": \"mbak\", \"mending\": \"lebih baik\", \"mgkn\": \"mungkin\", \"mhn\": \"mohon\", \"miker\": \"minuman keras\", \"milis\": \"mailing list\", \"mksd\": \"maksud\", \"mls\": \"malas\", \"mnt\": \"minta\", \"moge\": \"motor gede\", \"mokat\": \"mati\", \"mosok\": \"masa\", \"msh\": \"masih\", \"mskpn\": \"meskipun\", \"msng2\": \"masing-masing\", \"muahal\": \"mahal\", \"muker\": \"musyawarah kerja\", \"mumet\": \"pusing\", \"muna\": \"munafik\", \"munaslub\": \"musyawarah nasional luar biasa\", \"musda\": \"musyawarah daerah\", \"muup\": \"maaf\", \"muuv\": \"maaf\", \"nal\": \"kenal\", \"nangis\": \"menangis\", \"naon\": \"apa\", \"napol\": \"narapidana politik\", \"naq\": \"anak\", \"narsis\": \"bangga pada diri sendiri\", \"nax\": \"anak\", \"ndak\": \"tidak\", \"ndut\": \"gendut\", \"nekolim\": \"neokolonialisme\", \"nelfon\": \"menelepon\", \"ngabis2in\": \"menghabiskan\", \"ngakak\": \"tertawa\", \"ngambek\": \"marah\", \"ngampus\": \"pergi ke kampus\", \"ngantri\": \"mengantri\", \"ngapain\": \"sedang apa\", \"ngaruh\": \"berpengaruh\", \"ngawur\": \"berbicara sembarangan\", \"ngeceng\": \"kumpul bareng-bareng\", \"ngeh\": \"sadar\", \"ngekos\": \"tinggal di kos\", \"ngelamar\": \"melamar\", \"ngeliat\": \"melihat\", \"ngemeng\": \"bicara terus-terusan\", \"ngerti\": \"mengerti\", \"nggak\": \"tidak\", \"ngikut\": \"ikut\", \"nginep\": \"menginap\", \"ngisi\": \"mengisi\", \"ngmg\": \"bicara\", \"ngocol\": \"lucu\", \"ngomongin\": \"membicarakan\", \"ngumpul\": \"berkumpul\", \"ni\": \"ini\", \"nyasar\": \"tersesat\", \"nyariin\": \"mencari\", \"nyiapin\": \"mempersiapkan\", \"nyiram\": \"menyiram\", \"nyok\": \"ayo\", \"o/\": \"oleh\", \"ok\": \"ok\", \"priksa\": \"periksa\", \"pro\": \"profesional\", \"psn\": \"pesan\", \"psti\": \"pasti\", \"puanas\": \"panas\", \"qmo\": \"kamu\", \"qt\": \"kita\", \"rame\": \"ramai\", \"raskin\": \"rakyat miskin\", \"red\": \"redaksi\", \"reg\": \"register\", \"rejeki\": \"rezeki\", \"renstra\": \"rencana strategis\", \"reskrim\": \"reserse kriminal\", \"sni\": \"sini\", \"somse\": \"sombong sekali\", \"sorry\": \"maaf\", \"sosbud\": \"sosial-budaya\", \"sospol\": \"sosial-politik\", \"sowry\": \"maaf\", \"spd\": \"sepeda\", \"sprti\": \"seperti\", \"spy\": \"supaya\", \"stelah\": \"setelah\", \"subbag\": \"subbagian\", \"sumbangin\": \"sumbangkan\", \"sy\": \"saya\", \"syp\": \"siapa\", \"tabanas\": \"tabungan pembangunan nasional\", \"tar\": \"nanti\", \"taun\": \"tahun\", \"tawh\": \"tahu\", \"tdi\": \"tadi\", \"te2p\": \"tetap\", \"tekor\": \"rugi\", \"telkom\": \"telekomunikasi\", \"telp\": \"telepon\", \"temen2\": \"teman-teman\", \"tengok\": \"menjenguk\", \"terbitin\": \"terbitkan\", \"tgl\": \"tanggal\", \"thanks\": \"terima kasih\", \"thd\": \"terhadap\", \"thx\": \"terima kasih\", \"tipi\": \"TV\", \"tkg\": \"tukang\", \"tll\": \"terlalu\", \"tlpn\": \"telepon\", \"tman\": \"teman\", \"tmbh\": \"tambah\", \"tmn2\": \"teman-teman\", \"tmph\": \"tumpah\", \"tnda\": \"tanda\", \"tnh\": \"tanah\", \"togel\": \"toto gelap\", \"tp\": \"tapi\", \"tq\": \"terima kasih\", \"trgntg\": \"tergantung\", \"trims\": \"terima kasih\", \"cb\": \"coba\", \"y\": \"ya\", \"munfik\": \"munafik\", \"reklamuk\": \"reklamasi\", \"sma\": \"sama\", \"tren\": \"trend\", \"ngehe\": \"kesal\", \"mz\": \"mas\", \"analisise\": \"analisis\", \"sadaar\": \"sadar\", \"sept\": \"september\", \"nmenarik\": \"menarik\", \"zonk\": \"bodoh\", \"rights\": \"benar\", \"simiskin\": \"miskin\", \"ngumpet\": \"sembunyi\", \"hardcore\": \"keras\", \"akhirx\": \"akhirnya\", \"solve\": \"solusi\", \"watuk\": \"batuk\", \"ngebully\": \"intimidasi\", \"masy\": \"masyarakat\", \"still\": \"masih\", \"tauk\": \"tahu\", \"mbual\": \"bual\", \"tioghoa\": \"tionghoa\", \"ngentotin\": \"senggama\", \"kentot\": \"senggama\", \"faktakta\": \"fakta\", \"sohib\": \"teman\", \"rubahnn\": \"rubah\", \"trlalu\": \"terlalu\", \"nyela\": \"cela\", \"heters\": \"pembenci\", \"nyembah\": \"sembah\", \"most\": \"paling\", \"ikon\": \"lambang\", \"light\": \"terang\", \"pndukung\": \"pendukung\", \"setting\": \"atur\", \"seting\": \"akting\", \"next\": \"lanjut\", \"waspadalah\": \"waspada\", \"gantengsaya\": \"ganteng\", \"parte\": \"partai\", \"nyerang\": \"serang\", \"nipu\": \"tipu\", \"ktipu\": \"tipu\", \"jentelmen\": \"berani\", \"buangbuang\": \"buang\", \"tsangka\": \"tersangka\", \"kurng\": \"kurang\", \"ista\": \"nista\", \"less\": \"kurang\", \"koar\": \"teriak\", \"paranoid\": \"takut\", \"problem\": \"masalah\", \"tahi\": \"kotoran\", \"tirani\": \"tiran\", \"tilep\": \"tilap\", \"happy\": \"bahagia\", \"tak\": \"tidak\", \"penertiban\": \"tertib\", \"uasai\": \"kuasa\", \"mnolak\": \"tolak\", \"trending\": \"trend\", \"taik\": \"tahi\", \"wkwkkw\": \"tertawa\", \"ahokncc\": \"ahok\", \"istaa\": \"nista\", \"benarjujur\": \"jujur\", \"mgkin\": \"mungkin\"}\n",
    "\n",
    "def normalisasi(docs):\n",
    "    hasil_normalisasi = []\n",
    "    for doc in range(len(docs)):\n",
    "        hasil_normalisasi.append([])\n",
    "        for d in docs[doc]:\n",
    "            if ((d != '') or (d != \"\")):\n",
    "                hasil_normalisasi[doc].append(normal_word[d] if d in normal_word else d)\n",
    "    return hasil_normalisasi\n",
    "\n",
    "list_file = normalisasi(list_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0b7e3",
   "metadata": {},
   "source": [
    "## 2. INVERTED INDEX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c6bdd1",
   "metadata": {},
   "source": [
    "Pada penugasan nomor 2 ini akan memanfaatkan hasil preprocessing pada penugasan no 1 sebelumnya untuk dibuat _inverted index_-nya. nverted index adalah sebuah struktur data index yang dibangun untuk memudahkan query pencarian yang memotong tiap kata (term) yang berbeda dari suatu daftar term dokumen. Inverted index memiliki tujuan untuk meningkatkan kecepatan dan efisiensi dalam melakukan pencarian pada sekumpulan dokumen dan menemukan dokumen-dokumen yang mengandung query user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06becbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menyiapkan dictionary kosong dengan nama inverted_index\n",
    "inverted_index = {}\n",
    "\n",
    "for i in range(len(list_file)):\n",
    "    for item in list_file[i]:\n",
    "        if item not in inverted_index:\n",
    "            inverted_index[item] = []\n",
    "        if (item in inverted_index) and ((i+1) not in inverted_index[item]):\n",
    "            inverted_index[item].append(i+1)\n",
    "print(inverted_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac89c37",
   "metadata": {},
   "source": [
    "Dari hasil _inverted index_ di atas terlihat bahwa terdapat struktur data _dictionary_ dengan semua token (term) dari semua file berita sebelumnya yang telah melalui proses preprocessing. Selain itu terdapat juga index atau referensi dimana kata tersebut berada. Misalkan untuk kata 'covid' berada pada dokumen ke 1,2,3,4,5 atau dengan kata lain kata 'covid' berada pada keseluruhan dokumen. Dari hasil inilah nantinya adakan digunakan untuk _boolean retrieval model_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8250f76c",
   "metadata": {},
   "source": [
    "## 4. TERM WEIGHTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afc482ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming_sentence(text):\n",
    "    output = \"\"\n",
    "    for token in tokenisasi(text):\n",
    "        output = output + stemming(token) + \" \"\n",
    "    return output[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5908c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def termFrequencyInDoc(vocab, doc_dict) :\n",
    "    tf_docs = {}\n",
    "    for doc_id in doc_dict.keys() :\n",
    "        tf_docs[doc_id] = {}\n",
    "    for word in vocab :\n",
    "        for doc_id, doc in doc_dict.items() :\n",
    "            tf_docs[doc_id][word] = doc.count(word)\n",
    "    \n",
    "    return tf_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42b15bb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inverted_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vocab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43minverted_index\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m      2\u001b[0m doc_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      4\u001b[0m doc_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(list_file[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inverted_index' is not defined"
     ]
    }
   ],
   "source": [
    "vocab = list(inverted_index.keys())\n",
    "doc_dict = {}\n",
    "\n",
    "doc_dict['doc1'] = ' '.join(list_file[0])\n",
    "doc_dict['doc2'] = ' '.join(list_file[1])\n",
    "doc_dict['doc3'] = ' '.join(list_file[2])\n",
    "doc_dict['doc4'] = ' '.join(list_file[3])\n",
    "doc_dict['doc5'] = ' '.join(list_file[4])\n",
    "\n",
    "print(doc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33462dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(termFrequencyInDoc(vocab, doc_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e095144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88127975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordDocFre(vocab, doc_dict) :\n",
    "    df = {}\n",
    "    for word in vocab :\n",
    "        frq = 0\n",
    "        for doc in doc_dict.values() :\n",
    "            if word in doc :\n",
    "                frq = frq + 1\n",
    "        df[word] = frq\n",
    "        \n",
    "    return df\n",
    "\n",
    "print(wordDocFre(vocab, doc_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e126449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def inverseDocFre(vocab, doc_fre, length) :\n",
    "    idf = {} \n",
    "    for word in vocab :\n",
    "        idf[word] = 1 + np.log10((length + 1) / (doc_fre[word] + 1))\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7957ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inverseDocFre(vocab, wordDocFre(vocab, doc_dict), len(doc_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc1e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import operator\n",
    "\n",
    "idf_file = inverseDocFre(vocab, wordDocFre(vocab, doc_dict), len(doc_dict))\n",
    "\n",
    "idf_max = max(idf_file, key = idf_file.get)\n",
    "# idf_max = max(idf_file.items(), key = operator.itemgetter(1))[0]\n",
    "\n",
    "print(\"Maximum IDF value (Key): \", idf_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e0c7f9",
   "metadata": {},
   "source": [
    "## 5. VECTOR SPACE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e49b404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(vocab, tf, idf_scr, doc_dict) :\n",
    "    tf_idf_scr = {}\n",
    "    for doc_id in doc_dict.keys() :\n",
    "        tf_idf_scr[doc_id] = {}\n",
    "    for word in vocab :\n",
    "        for doc_id, doc in doc_dict.items() :\n",
    "            tf_idf_scr[doc_id][word] = tf[doc_id][word] * idf_scr[word]\n",
    "    \n",
    "    return tf_idf_scr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca8acfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tf_idf \u001b[38;5;241m=\u001b[39m \u001b[43mtfidf\u001b[49m(vocab, termFrequencyInDoc(vocab, doc_dict), inverseDocFre(vocab, wordDocFre(vocab, doc_dict), \u001b[38;5;28mlen\u001b[39m(doc_dict)), doc_dict)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf_idf)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Term - Document Matrix\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "tf_idf = tfidf(vocab, termFrequencyInDoc(vocab, doc_dict), inverseDocFre(vocab, wordDocFre(vocab, doc_dict), len(doc_dict)), doc_dict)\n",
    "print(tf_idf)\n",
    "\n",
    "# Term - Document Matrix\n",
    "TD = np.zeros((len(vocab), len(doc_dict)))\n",
    "\n",
    "print(cosine_sim(TQ[:, 0], TD[:, 2])) #query & doc3print(\"\\n\\nMatrix\\n\")\n",
    "for word in vocab :\n",
    "    for doc_id, doc in tf_idf.items() :\n",
    "        ind1 = vocab.index(word)\n",
    "        ind2 = list(tf_idf.keys()).index(doc_id)\n",
    "        TD[ind1][ind2] = tf_idf[doc_id][word]\n",
    "\n",
    "print(TD)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac400b3",
   "metadata": {},
   "source": [
    "## 6. TEXT SIMILARITY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3251957f",
   "metadata": {},
   "source": [
    "### 6.4. Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc22d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def cosine_sim(vec1, vec2) :\n",
    "    vec1 = list(vec1)\n",
    "    vec2 = list(vec2)\n",
    "    dot_prod = 0\n",
    "    for i, v in enumerate(vec1) :\n",
    "        dot_prod += v * vec2[i]\n",
    "    mag_1 = math.sqrt(sum([x**2 for x in vec1]))\n",
    "    mag_2 = math.sqrt(sum([x**2 for x in vec2]))\n",
    "    \n",
    "    return dot_prod / (mag_1 * mag_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e85f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cosine SImilarity Doc1 & Doc2: \", cosine_sim(TD[:, 0], TD[:, 1])) # doc1 dan doc2\n",
    "print(\"Cosine SImilarity Doc1 & Doc2: \", cosine_sim(TD[:, 0], TD[:, 2])) # doc1 dan doc3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4608af8a",
   "metadata": {},
   "source": [
    "## 7. Exact Top K Document Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0667c102",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = inverseDocFre(vocab,wordDocFre(vocab,doc_dict),len(doc_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a93dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"vaksin corona jakarta\"\n",
    "def termFrequency(vocab, query):\n",
    "    tf_query = {}\n",
    "    for word in vocab:\n",
    "        tf_query[word] = query.count(word)\n",
    "    return tf_query\n",
    "tf_query = termFrequency(vocab, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd20990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term - Query Matrix\n",
    "TQ = np.zeros((len(vocab), 1)) #hanya 1 query\n",
    "for word in vocab:\n",
    "    ind1 = vocab.index(word)\n",
    "    TQ[ind1][0] = tf_query[word]*idf[word]\n",
    "print(TQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c5382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"doc1 : \", cosine_sim(TQ[:, 0], TD[:, 0])) #query & doc1\n",
    "print(\"doc2 : \", cosine_sim(TQ[:, 0], TD[:, 1])) #query & doc2\n",
    "print(\"doc3 : \", cosine_sim(TQ[:, 0], TD[:, 2])) #query & doc3\n",
    "print(\"doc4 : \", cosine_sim(TQ[:, 0], TD[:, 3])) #query & doc4\n",
    "print(\"doc5 : \", cosine_sim(TQ[:, 0], TD[:, 4])) #query & doc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be16984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def exact_top_k(doc_dict, TD, q, k):\n",
    "    relevance_scores = {}\n",
    "    i = 0\n",
    "    for doc_id in doc_dict.keys():\n",
    "        relevance_scores[doc_id] = cosine_sim(q, TD[:, i])\n",
    "        i = i + 1\n",
    "    sorted_value = OrderedDict(sorted(relevance_scores.items(), key=lambda x: x[1], reverse = True))\n",
    "    top_k = {j: sorted_value[j] for j in list(sorted_value)[:k]}\n",
    "    return top_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a257d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = exact_top_k(doc_dict, TD, TQ[:, 0], 5)\n",
    "print(top_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858862ca",
   "metadata": {},
   "source": [
    "## 8. PROBABILISTIC IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8603c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "tokenized_corpus = [tokenisasi2(doc_dict[doc_id]) for doc_id in doc_dict]\n",
    "print(tokenized_corpus)\n",
    "\n",
    "query = \"vaksin corona jakarta\"\n",
    "tokenized_query = tokenisasi2(query)\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "doc_scores = bm25.get_scores(tokenized_query)\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b65f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def exact_top_k_2(doc_dict, rank_score, k) :\n",
    "    relevance_scores = {}\n",
    "    i = 0\n",
    "    for doc_id in doc_dict.keys() :\n",
    "        relevance_scores[doc_id] = rank_score[i]\n",
    "        i = i + 1\n",
    "    \n",
    "    sorted_value = OrderedDict(sorted(relevance_scores.items(), key = lambda x: x[1], reverse = True))\n",
    "    top_k = {j : sorted_value[j] for j in list(sorted_value)[:k]}\n",
    "    return top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_top_k_2(doc_dict, doc_scores, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c213ff12",
   "metadata": {},
   "source": [
    "Setelah hasil Exact Top K BM25 dibandingkan dengan hasil Exact Top K Cosine Similarity didapati bahwa dokumen yang menduduki posisi tiga teratas dengan query \"vaksin corona jaarta\" adalah berbeda.\n",
    "Exact Top K BM25       : doc3, doc2, doc5\n",
    "Exact Top K Cosine Sim : doc2, doc3, doc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de16582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(TQ[:, 0]))\n",
    "print(TD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4bf389",
   "metadata": {},
   "source": [
    "## LANGUAGE MODELS FOR INFORMATION RETRIEVAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c7b69f",
   "metadata": {},
   "source": [
    "### Standar Query Likelihood Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6aa67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_scores = {}\n",
    "vocab = set()\n",
    "for doc_id in doc_dict.keys() :\n",
    "    likelihood_scores[doc_id] = 1\n",
    "    tokens = tokenisasi2(doc_dict[doc_id])\n",
    "    vocab.update(tokens)\n",
    "    for q in tokenized_query :\n",
    "        likelihood_scores[doc_id] = likelihood_scores[doc_id]*tokens.count(q)/len(tokens)\n",
    "print(likelihood_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffff16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def exact_top_k_3(doc_dict, rank_score, k) :\n",
    "    sorted_value = OrderedDict(sorted(rank_score.items(), key = lambda x: x[1], reverse = True))\n",
    "    top_k = {j : sorted_value[j] for j in list(sorted_value)[:k]}\n",
    "    return top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266d221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_top_k_3(doc_dict, likelihood_scores, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a77c12e",
   "metadata": {},
   "source": [
    "### Laplace Smoothing α = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782437f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menggunakan teknik smoothing untuk menghindari peluang bernilai 0 pada unseen word\n",
    "tokenized_corpus = [j for sub in [tokenisasi2(doc_dict[doc_id]) for doc_id in doc_dict] for j in sub]\n",
    "vocab = set(tokenized_corpus)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9960ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menerapkan Laplace smoothing pada query likelihood model dengan alpha = 1\n",
    "alpha = 1\n",
    "likelihood_scores = {}\n",
    "for doc_id in doc_dict.keys():\n",
    "    likelihood_scores[doc_id] = 1\n",
    "    tokens = tokenisasi2(doc_dict[doc_id])\n",
    "    for q in tokenized_query:\n",
    "        likelihood_scores[doc_id]=likelihood_scores[doc_id]*(tokens.count(q)+alpha)/(len(tokens)+len(vocab)*alpha)\n",
    "print(likelihood_scores)\n",
    "exact_top_k_3(doc_dict, likelihood_scores, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da46c94",
   "metadata": {},
   "source": [
    "### Jelinek-Mercher Smoothing λ = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceca699",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamda = 0.5\n",
    "likelihood_scores = {}\n",
    "for doc_id in doc_dict.keys():\n",
    "    likelihood_scores[doc_id] = 1\n",
    "    tokens = tokenisasi2(doc_dict[doc_id])\n",
    "    for q in tokenized_query:\n",
    "        likelihood_scores[doc_id]=likelihood_scores[doc_id]*((lamda*tokens.count(q)/len(tokens))+((1-lamda)*tokenized_corpus.count(q)/len(tokenized_corpus)))\n",
    "print(likelihood_scores)\n",
    "exact_top_k_3(doc_dict, likelihood_scores, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ce35ff",
   "metadata": {},
   "source": [
    "### Dirichlet Smoothing μ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617dd8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "miu = 2\n",
    "likelihood_scores = {}\n",
    "for doc_id in doc_dict.keys():\n",
    "    likelihood_scores[doc_id] = 1\n",
    "    tokens = tokenisasi2(doc_dict[doc_id])\n",
    "    for q in tokenized_query:\n",
    "        likelihood_scores[doc_id]=likelihood_scores[doc_id]*(tokens.count(q)+miu*tokenized_corpus.count(q)/len(tokenized_corpus))/(len(tokens)+miu)\n",
    "print(likelihood_scores)\n",
    "exact_top_k_3(doc_dict, likelihood_scores, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fcd562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374bcd07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
